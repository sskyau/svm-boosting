{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d646aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981f3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c82b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    accuracy=np.sum(y_true==y_pred)/len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed88ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"movie_review_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7baca54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82813cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ed1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import stop words for eliminating undesired words\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e449c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d6c735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[0,1,2,3,4,5,6,7,8,9]\n",
    "for i in range(len(df)):\n",
    "    asd=df[\"review\"][i]\n",
    "    filtered_list=list()\n",
    "    s=\"\"\n",
    "    ##tokenize the words\n",
    "    for word in word_tokenize(asd):\n",
    "        ## convert all leters to lower letters\n",
    "        ## discard the stopwords\n",
    "        if word.casefold() not in stop_words:\n",
    "            ss=\"\"\n",
    "            \n",
    "            for ae in word.casefold():\n",
    "                try:\n",
    "                    if int(ae) in aa:\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    ss+=ae\n",
    "            ## lemmitize the words\n",
    "            asd2=lemmatizer.lemmatize(ss)\n",
    "            ## discard punctuations\n",
    "            asd2=tokenizer.tokenize(asd2)\n",
    "            if len(asd2)!=0:\n",
    "                if len(asd2[0])>1:\n",
    "                    asd2=\"\".join(asd2)\n",
    "                    s+=asd2\n",
    "                    s+=\" \"\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    ## update the column names \n",
    "    df[\"review\"][i]=s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2365c0",
   "metadata": {},
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "training_data, testing_data = train_test_split(df, test_size=0.2, random_state=25)\n",
    "training_data.index=list(range(0,len(training_data)))\n",
    "testing_data.index=list(range(0,len(testing_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85468b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2014d7",
   "metadata": {},
   "source": [
    "# td=[]\n",
    "for i in training_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td.append(sen)\n",
    "    \n",
    "td2=[]\n",
    "for i in testing_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td2.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0934ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "td=[]\n",
    "for i in training_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td.append(sen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7e2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "vectorizer.fit(td)\n",
    "vector_train = vectorizer.transform(td)\n",
    "#vector_test=vectorizer.transform(td2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9756ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd=vector_train.toarray()\n",
    "#asd2=vector_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ef85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=training_data[\"sentiment\"]\n",
    "#y_test=testing_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc66c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train==\"negative\"]=\"-1\"\n",
    "y_train[y_train==\"positive\"]=\"1\"\n",
    "#y_test[y_test==\"negative\"]=\"-1\"\n",
    "#y_test[y_test==\"positive\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdddb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.DataFrame(asd)\n",
    "#dff2=pd.DataFrame(asd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2393d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.index=range(len(y_train))\n",
    "#y_test.index=range(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137e772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost2:\n",
    "    \n",
    "    def __init__(self,n_clf=50):\n",
    "        self.n_clf=n_clf\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        n_samples,n_features=X.shape\n",
    "        w=np.full(n_samples,(1/n_samples))\n",
    "        self.clfs=[]\n",
    "        self.alpha=[]\n",
    "        \n",
    "        for _ in range(self.n_clf):\n",
    "            \n",
    "            clf=DecisionTreeClassifier(max_depth=3)\n",
    "            clf=clf.fit(X, y,sample_weight=w)\n",
    "            min_error=float('inf')\n",
    "            \n",
    "           \n",
    "            predictions=clf.predict(X)\n",
    "            missclassified=w[y!=predictions]\n",
    "            error=sum(missclassified)\n",
    "\n",
    "            if error>0.5:\n",
    "                error=1-error\n",
    "                \n",
    "            if error < min_error:\n",
    "                min_error=error\n",
    "                \n",
    "\n",
    "            EPS=1e-10           \n",
    "            self.alpha.append(0.5*np.log((1-error)/(error+EPS)))\n",
    "            predictions=clf.predict(X)\n",
    "    \n",
    "            \n",
    "            asd4=list()\n",
    "            e=-(0.5*np.log((1-error)/(error+EPS)))\n",
    "            for i in range(len(predictions)):\n",
    "                if predictions[i]==y[i]:\n",
    "                    asd4.append(1)\n",
    "                else:\n",
    "                    asd4.append(-1)\n",
    "                    \n",
    "            \n",
    "            w*=np.exp(e*np.array(asd4))\n",
    "            w/=np.sum(w)\n",
    "            \n",
    "            self.clfs.append(clf)\n",
    "            \n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        clf_preds=list()\n",
    "        for index in range(len(self.alpha)):\n",
    "            asd=self.clfs[index]\n",
    "            res=asd.predict(X)\n",
    "            res2=[int(i) for i in res]\n",
    "            clf_preds.append(self.alpha[index]*np.array(res2))\n",
    "        y_pred=np.sum(clf_preds,axis=0)\n",
    "        y_pred=np.sign(y_pred)\n",
    "        y_pred=[str(i) for i in y_pred]\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==\"-1.0\":\n",
    "                y_pred[i]=\"-1\"\n",
    "            else:\n",
    "                y_pred[i]=\"1\"\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d860569",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=AdaBoost2(n_clf=50)\n",
    "clf.fit(dff,y_train)\n",
    "#y_pred=clf.predict(dff2)\n",
    "#acc=accuracy(y_test,y_pred)\n",
    "#print(\"Accuracy :\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004720bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"movie_review_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[0,1,2,3,4,5,6,7,8,9]\n",
    "for i in range(len(test_data)):\n",
    "    asd=test_data[\"review\"][i]\n",
    "    filtered_list=list()\n",
    "    s=\"\"\n",
    "    ##tokenize the words\n",
    "    for word in word_tokenize(asd):\n",
    "        ## convert all leters to lower letters\n",
    "        ## discard the stopwords\n",
    "        if word.casefold() not in stop_words:\n",
    "            ss=\"\"\n",
    "            \n",
    "            for ae in word.casefold():\n",
    "                try:\n",
    "                    if int(ae) in aa:\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    ss+=ae\n",
    "            ## lemmitize the words\n",
    "            asd2=lemmatizer.lemmatize(ss)\n",
    "            ## discard punctuations\n",
    "            asd2=tokenizer.tokenize(asd2)\n",
    "            if len(asd2)!=0:\n",
    "                if len(asd2[0])>1:\n",
    "                    asd2=\"\".join(asd2)\n",
    "                    s+=asd2\n",
    "                    s+=\" \"\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    ## update the column names \n",
    "    test_data[\"review\"][i]=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_test=[]\n",
    "for i in test_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td_test.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087cfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "vectorizer.fit(td)\n",
    "vector_predict = vectorizer.transform(td_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test==\"negative\"]=\"-1\"\n",
    "y_test[y_test==\"positive\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db048715",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_test=vector_predict.toarray()\n",
    "dff_test=pd.DataFrame(asd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(dff_test)\n",
    "acc=accuracy(y_test,y_pred)\n",
    "print(\"Accuracy :\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380e222",
   "metadata": {},
   "source": [
    "# Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40797022",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "td=[]\n",
    "for i in training_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(td)\n",
    "vector_train = vectorizer.transform(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6dcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd=vector_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15355192",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=training_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef097b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train==\"negative\"]=\"-1\"\n",
    "y_train[y_train==\"positive\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.DataFrame(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.index=range(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6369e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=AdaBoost2(n_clf=50)\n",
    "clf.fit(dff,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f91dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"movie_review_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a03591",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[0,1,2,3,4,5,6,7,8,9]\n",
    "for i in range(len(test_data)):\n",
    "    asd=test_data[\"review\"][i]\n",
    "    filtered_list=list()\n",
    "    s=\"\"\n",
    "    ##tokenize the words\n",
    "    for word in word_tokenize(asd):\n",
    "        ## convert all leters to lower letters\n",
    "        ## discard the stopwords\n",
    "        if word.casefold() not in stop_words:\n",
    "            ss=\"\"\n",
    "            \n",
    "            for ae in word.casefold():\n",
    "                try:\n",
    "                    if int(ae) in aa:\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    ss+=ae\n",
    "            ## lemmitize the words\n",
    "            asd2=lemmatizer.lemmatize(ss)\n",
    "            ## discard punctuations\n",
    "            asd2=tokenizer.tokenize(asd2)\n",
    "            if len(asd2)!=0:\n",
    "                if len(asd2[0])>1:\n",
    "                    asd2=\"\".join(asd2)\n",
    "                    s+=asd2\n",
    "                    s+=\" \"\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    ## update the column names \n",
    "    test_data[\"review\"][i]=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65182125",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_test=[]\n",
    "for i in test_data[\"review\"]:\n",
    "    sen=\"\".join(i)\n",
    "    td_test.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc472a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(td)\n",
    "vector_predict = vectorizer.transform(td_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305beb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test==\"negative\"]=\"-1\"\n",
    "y_test[y_test==\"positive\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedfc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd_test=vector_predict.toarray()\n",
    "dff_test=pd.DataFrame(asd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d98978",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(dff_test)\n",
    "acc=accuracy(y_test,y_pred)\n",
    "print(\"Accuracy :\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89943b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
